{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37odMBPjHyob"
   },
   "source": [
    "# *TP1 - DEEP LEARNING*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tghqWAdqHyob"
   },
   "source": [
    "# Partie 1 : _Formalisation mathématique_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour appliquer un réseau de neurones à un problème de machine learning (en apprentissage supervisé),\n",
    "on a besoin de 4 choses :\n",
    "\n",
    "- Un jeu de données annoté et un problème associé ;\n",
    "- Une architecture de réseau (à adapter aux données) ;\n",
    "- Une fonction de coût que l’on cherche à minimiser (à adapter au problème) ;\n",
    "- Un algorithme d’apprentissage pour résoudre le problème d’optimisation consistant à minimiser\n",
    "cette fonction de coût.\n",
    "\n",
    "On s'intéresse ici à un problème de classification en apprentissage supervisé. On a donc un jeu de données constitué d'un ensemble de $N$ couples $ (x^{(i)}, y^{(i)}) $, où $ i \\in \\{1, ..., N\\} $, $ x^{(i)} \\in \\mathbb{R}^{n_x} $ est un vecteur de _features_ à partir duquel on veut prédire la vérité terrain $ y^{(i)} \\in \\{0, 1\\}^{n_y} $ vérifiant $ \\|y^{(i)}\\| = 1 $ (_one hot encoding_). \n",
    "\n",
    "Ce jeu de données est généralement découpé en plusieurs ensembles : **train**, **test** et parfois **val**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3744XSfKHyob"
   },
   "source": [
    "### Q1. A quoi servent les ensembles d’apprentissage, de validation et de test ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train : ajuster les paramètres du modèle.\n",
    "Validation (val) : choisir l’architecture / hyperparamètres et détecter le surapprentissage.\n",
    "Test : évaluer la performance finale sur des données jamais vues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAMIxCJWHyoc"
   },
   "source": [
    "### Q2. Quelle est l’influence du nombre $N$ d’exemples ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus N est grand, meilleure est l’estimation des paramètres, moins de variance et meilleure généralisation (si qualité des labels stable).\n",
    "Trop peu d’exemples → surapprentissage ; données bruitées → performance limitée même si N grand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnlVKmAPHyoc"
   },
   "source": [
    "#### Q3. Pourquoi est-il important d’ajouter des fonctions d’activation entre des transformations lineaires ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour introduire la non-linéarité permettant d’approximer des fonctions complexes ; sans elles, le réseau reste une transformation linéaire unique quelle que soit la profondeur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoFD1mF5Hyoe"
   },
   "source": [
    "#### Q4. Quelles sont les tailles $ n_{x}, n_{h}, n_{y} $ sur la figure 1  ? En pratique, comment ces tailles sont-elles choisies ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_x : dimension des features d’entrée.\n",
    "n_h : nombre d’unités dans la couche cachée (taille latente / capacité).\n",
    "n_y : nombre de classes (dimension de la sortie one-hot).\n",
    "Choix pratique : n_x et n_y sont dictés par les données ; n_h choisi par validation croisée / contraintes de calcul en équilibrant sous- et surcapacité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sl8NKiWIHyoe"
   },
   "source": [
    "#### Q5. Que représentent les vecteurs $ y $ et $ \\hat{y} $ ? Quelle est la différence entre ces deux quantités ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y : vérité terrain (one-hot) indiquant la classe réelle.\n",
    "ŷ : prédiction probabiliste du modèle (vecteur de scores / probabilités).\n",
    "Différence : y est binaire/indicateur, ŷ est continu (probabilités) ; objectif : rapprocher ŷ de y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIED5B0SHyof"
   },
   "source": [
    "#### Q6. Pourquoi utiliser une fonction $ SoftMax $ en sortie ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertit les scores en probabilités positives qui somment à 1, permettant interprétation probabiliste et usage direct avec la cross-entropy pour classification multi-classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZIbE0MuHyof"
   },
   "source": [
    "#### Q7. Écrire les équations mathématiques permettant d'effectuer la passe forward du réseau de neurones, produisant successivement $ \\tilde{h}, \\hat{h}, \\tilde{y}, $ et $ \\hat{y} $ à partir de $ x $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\tilde{h} = W^{(1)} x + b^{(1)}\n",
    "\\hat{h} = f(\\tilde{h}) (activation, ex. ReLU, tanh)\n",
    "\\tilde{y} = W^{(2)} \\hat{h} + b^{(2)}\n",
    "\\hat{y} = softmax(\\tilde{y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EyKp7e_Hyof"
   },
   "source": [
    "#### Q8. Pendant l’apprentissage, on cherche à minimiser la fonction de coût. Pour l’entropie croisée et l’erreur quadratique, comment les $ \\hat{y}_i $ doivent-ils varier pour faire diminuer la loss ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-entropy : augmenter la probabilité ŷ_c de la vraie classe c (tendre vers 1) et diminuer les autres.\n",
    "MSE (avec one-hot) : rapprocher chaque composante ŷ_i de y_i (pour la vraie classe augmenter vers 1, les autres vers 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0WWLSBUHyof"
   },
   "source": [
    "#### Q9. En quoi ces fonctions sont-elles plus adaptées aux problèmes de classification ou de régression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification multi-classe : softmax + cross-entropy.\n",
    "Classification binaire : sigmoid + binary cross-entropy.\n",
    "Régression : sorties continues + MSE ou autres pertes adaptées (MAE, Huber)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moNmwesbHyof"
   },
   "source": [
    "#### Q10. Quels semblent etre les avantages et inconvenients des diverses variantes de descente de gradient entre les versions classique, stochastique sur mini-batch et stochastique online ? Laquelle semble la plus raisonnable a utiliser dans le cas general ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch (toute la dataset) : gradients exacts, couteux en mémoire et temps pour grands jeux de données.\n",
    "Online (un échantillon) : très bruité, converge vite mais instable.\n",
    "Mini-batch : compromis pratique (stabilité, efficacité GPU, bruit utile pour évasion minima locaux).\n",
    "Recommandation générale : mini-batch SGD (taille choisie selon mémoire / variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q11. Quelle est l’influence du learning rate $ η $ sur l’apprentissage ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trop grand → divergence / oscillations ; trop petit → convergence lente, risque de rester bloqué.\n",
    "Utiliser schedule/adaptatif (decay, Adam, etc.) et régler par validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q12. Comparer la complexité (en fonction du nombre de couches du réseau)  du calcul des gradients de la loss par rapport aux paramètres, en utilisant l'approche naïve et l'algorithme de l’algorithme de backprop ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naïve : recalculer dérivées séparément pour chaque paramètre entraîne coût multiplicatif (croissance exponentielle/linéaire en couches selon implémentation), très cher.\n",
    "Backprop : calcule gradients pour tous les paramètres en temps proportionnel à un petit multiple de la passe forward (complexité linéaire en nombre d’opérations du réseau), donc beaucoup plus efficace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q13. Quel critère doit respecter l’architecture du réseau pour permettre la backpropagation ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutes les opérations doivent être différentiables (au moins presque partout) et le graphe computationnel doit être acyclique ; les paramètres doivent influencer la sortie via ce graphe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q14. La fonction $ SoftMax $ et la loss de cross-entropy sont souvent utilisées ensemble et leur gradient est très simple. Montrez que la loss se simplifie en :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour logits \\tilde{y} et vraie classe c, la loss = -log softmax_c(\\tilde{y}) = -\\tilde{y}_c + log(∑_j exp(\\tilde{y}_j)).\n",
    "C’est la forme usuelle utilisée pour la stabilité numérique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q15. Écrire le gradient de la loss (cross-entropy) par rapport à la sortie intermédiaire $\\tilde{y}$ :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "∂L/∂\\tilde{y}_i = \\hat{y}_i - y_i (pour chaque composante i)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification: softmax + cross-entropy et gradient analytique\n",
    "import numpy as np\n",
    "def softmax(logits):\n",
    "    e = np.exp(logits - np.max(logits))\n",
    "    return e / e.sum()\n",
    "def cross_entropy_loss(logits, y_onehot):\n",
    "    s = softmax(logits)\n",
    "    return -np.log(s[y_onehot==1])\n",
    "# Exemple\n",
    "logits = np.array([2.0, 1.0, 0.1])\n",
    "y_onehot = np.array([1, 0, 0])\n",
    "s = softmax(logits)\n",
    "loss = cross_entropy_loss(logits, y_onehot)\n",
    "analytical_grad = s - y_onehot\n",
    "# gradient numérique via différences finies\n",
    "eps = 1e-6\n",
    "num_grad = np.zeros_like(logits)\n",
    "for i in range(len(logits)):\n",
    "    l = logits.copy()\n",
    "    l[i] += eps\n",
    "    lp = cross_entropy_loss(l, y_onehot)\n",
    "    l[i] -= 2*eps\n",
    "    lm = cross_entropy_loss(l, y_onehot)\n",
    "    num_grad[i] = (lp - lm) / (2*eps)\n",
    "print('logits:', logits)\n",
    "print('softmax:', np.round(s,6))\n",
    "print('loss:', float(loss))\n",
    "print('analytical_grad:', np.round(analytical_grad,6))\n",
    "print('numeric_grad:', np.round(num_grad,6))\n",
    "print('max abs diff:', np.max(np.abs(analytical_grad - num_grad)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
